# ComfyUI/custom_nodes/LMStudio_ImageToText/__init__.py
import base64, io, json, time, requests
from PIL import Image

class DINKI_LMStudio:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            # ‚úÖ Î™®Îì† ÏûÖÎ†•ÏùÑ ÏúÑÏ†ØÏúºÎ°ú Ï≤òÎ¶¨, imageÎäî ÏÑ†ÌÉù Ïó∞Í≤∞(ÏòµÏÖò)
            "required": {},
            "optional": {
                # üîò Assistant ÌÜ†Í∏Ä (Í∞ÄÏû• ÏúÑÏóê Ïò§ÎèÑÎ°ù Ï≤´ Ìï≠Î™©)
                "assistant_enabled": ("BOOLEAN", {"default": True}),

                # ‚úçÔ∏è ÌîÑÎ°¨ÌîÑÌä∏
                "user_prompt": ("STRING", {"multiline": True, "default": ""}),
                "system_prompt": ("STRING", {
                    "multiline": True,
                    "default": "You are a writer who creates prompts for generative AI images. Respond only with the final English prompt."
                }),

                # üñºÔ∏è Ïù¥ÎØ∏ÏßÄ(ÏòµÏÖò ÏÜåÏºì)
                "image": ("IMAGE",),

                # üß† Î™®Îç∏ & ÏÉùÏÑ± ÌååÎùºÎØ∏ÌÑ∞
                "model_key": ("STRING", {"default": "qwen/qwen3-vl-8b"}),
                "seed": ("INT", {"default": -1}),
                "max_tokens": ("INT", {"default": 1000, "min": 1, "max": 8192}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0}),
                "timeout_seconds": ("INT", {"default": 300}),

                # üßπ ÏÉùÏÑ± ÌõÑ Ïñ∏Î°úÎìú
                "auto_unload": ("BOOLEAN", {"default": False}),
                "unload_delay": ("INT", {"default": 0, "min": 0, "max": 600}),

                # üåê ÏÑúÎ≤Ñ
                "ip_address": ("STRING", {"default": "127.0.0.1"}),
                "port": ("INT", {"default": 1234, "min": 1, "max": 65535}),
            }
        }

    # Ï∂úÎ†•: ÎãµÎ≥Ä Î¨∏ÏûêÏó¥ ÌïòÎÇò
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("AI Answer Text",)
    FUNCTION = "run"
    CATEGORY = "DINKIssTyle/LLM"

    # --- helpers ---
    def _tensor_to_data_url(self, image_tensor):
        if image_tensor is None:
            return None
        if isinstance(image_tensor, list) and len(image_tensor) > 0:
            img = image_tensor[0]
        else:
            img = image_tensor
        import numpy as np
        arr = img.cpu().numpy() if hasattr(img, "cpu") else img
        if getattr(arr, "ndim", 0) == 4:
            arr = arr[0]  # (B,H,W,C) ‚Üí (H,W,C)
        arr = (arr * 255.0).clip(0, 255).astype("uint8")
        pil_img = Image.fromarray(arr)
        buf = io.BytesIO()
        pil_img.save(buf, format="PNG")
        return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")

    # --- main ---
    def run(
        self,
        assistant_enabled=True,
        user_prompt="",
        system_prompt="",
        image=None,
        model_key="qwen/qwen3-vl-8b",
        seed=-1,
        max_tokens=1000,
        temperature=0.7,
        timeout_seconds=300,
        auto_unload=False,
        unload_delay=0,
        ip_address="127.0.0.1",
        port=1234,
    ):
        # 1) Ìå®Ïä§Ïä§Î£® Î™®Îìú: ÌÜ†Í∏ÄÏù¥ Í∫ºÏ†∏ ÏûàÏúºÎ©¥ ÎÑ§Ìä∏ÏõåÌÅ¨ Ìò∏Ï∂ú ÏóÜÏù¥ ÌÖçÏä§Ìä∏Îßå Î∞òÌôò
        if not assistant_enabled:
            return (user_prompt or "",)

        # 2) ÏãúÎìú
        if seed == "randomize":
            seed = int(time.time_ns() % (2**31))

        # 3) Î©îÏãúÏßÄ Íµ¨ÏÑ± (Ïù¥ÎØ∏ÏßÄÍ∞Ä ÏûàÏúºÎ©¥ Î©ÄÌã∞Î™®Îã¨, ÏóÜÏúºÎ©¥ ÌÖçÏä§Ìä∏Îßå)
        url = f"http://{ip_address}:{port}/v1/chat/completions"
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        content = [{"type": "text", "text": user_prompt or "Describe the image or prompt."}]
        image_url = self._tensor_to_data_url(image)
        if image_url:  # Ïù¥ÎØ∏ÏßÄÍ∞Ä Ïó∞Í≤∞Îêú Í≤ΩÏö∞ÏóêÎßå Ìè¨Ìï®
            content.append({"type": "image_url", "image_url": {"url": image_url}})

        messages.append({"role": "user", "content": content})

        body = {
            "model": model_key,
            "messages": messages,
            "max_tokens": int(max_tokens),
            "temperature": float(temperature),
            "seed": int(seed),  # ÏùºÎ∂Ä ÎπåÎìúÏóêÏÑú Î¨¥ÏãúÎê† Ïàò ÏûàÏùå
        }

        # 4) Ìò∏Ï∂ú
        try:
            resp = requests.post(url, json=body, timeout=timeout_seconds)
            resp.raise_for_status()
            data = resp.json()
        except Exception as e:
            raise RuntimeError(f"LM Studio ÏöîÏ≤≠ Ïã§Ìå®: {e}")

        # 5) ÏùëÎãµ ÌååÏã±
        try:
            text = data["choices"][0]["message"]["content"]
        except Exception:
            text = json.dumps(data, ensure_ascii=False)

        # 6) ÏûêÎèô Ïñ∏Î°úÎìú(ÏÑ†ÌÉù)
        if auto_unload and unload_delay > 0:
            time.sleep(unload_delay)
            for u in [f"http://{ip_address}:{port}/v1/models/unload",
                      f"http://{ip_address}:{port}/v1/unload"]:
                try:
                    r = requests.post(u, json={"model": model_key}, timeout=5)
                    if r.ok:
                        break
                except Exception:
                    pass

        return (text,)

# Îì±Î°ù
NODE_CLASS_MAPPINGS = {
    "DINKI LM Studio Assistant": DINKI_LMStudio,
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "DINKI LM Studio Assistant": "DINKI LM Studio Assistant",
}
