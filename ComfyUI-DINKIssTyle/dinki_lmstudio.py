import base64, io, json, time, requests
import numpy as np
from PIL import Image

class DINKI_LMStudio:
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {},
            "optional": {
                "assistant_enabled": ("BOOLEAN", {"default": True}),
                "user_prompt": ("STRING", {"multiline": True, "default": ""}),
                "system_prompt": ("STRING", {
                    "multiline": True,
                    "default": "You are a writer who creates prompts for generative AI images. Respond only with the final English prompt."
                }),
                "image": ("IMAGE",),
                "model_key": ("STRING", {"default": "qwen/qwen3-vl-8b"}),
                "seed": ("INT", {"default": -1}),
                "max_tokens": ("INT", {"default": 1000, "min": 1, "max": 8192}),
                "temperature": ("FLOAT", {"default": 0.7, "min": 0.0, "max": 2.0}),
                "timeout_seconds": ("INT", {"default": 300}),
                "auto_unload": ("BOOLEAN", {"default": False}),
                "unload_delay": ("INT", {"default": 0, "min": 0, "max": 600}),
                "ip_address": ("STRING", {"default": "127.0.0.1"}),
                "port": ("INT", {"default": 1234, "min": 1, "max": 65535}),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("AI Answer Text",)
    FUNCTION = "run"
    CATEGORY = "DINKIssTyle/LLM"

    # --- helpers ---
    def _convert_single_image_to_base64(self, img_tensor):
        """Îã®Ïùº Ïù¥ÎØ∏ÏßÄ ÌÖêÏÑú(H,W,C)Î•º base64 Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò"""
        try:
            arr = img_tensor.cpu().numpy() if hasattr(img_tensor, "cpu") else img_tensor
            # Í∞í Ïä§ÏºÄÏùºÎßÅ Î∞è ÌÉÄÏûÖ Î≥ÄÌôò
            arr = (arr * 255.0).clip(0, 255).astype("uint8")
            pil_img = Image.fromarray(arr)
            
            buf = io.BytesIO()
            pil_img.save(buf, format="PNG")
            return "data:image/png;base64," + base64.b64encode(buf.getvalue()).decode("utf-8")
        except Exception as e:
            print(f"[üÖ≥INKIssTyle - Error]Image conversion: {e}")
            return None

    # --- main ---
    def run(
        self,
        assistant_enabled=True,
        user_prompt="",
        system_prompt="",
        image=None,
        model_key="qwen/qwen3-vl-8b",
        seed=-1,
        max_tokens=1000,
        temperature=0.7,
        timeout_seconds=300,
        auto_unload=False,
        unload_delay=0,
        ip_address="127.0.0.1",
        port=1234,
    ):
        # 1) Ìå®Ïä§Ïä§Î£® Î™®Îìú
        if not assistant_enabled:
            return (user_prompt or "",)

        # 2) ÏãúÎìú Ï≤òÎ¶¨
        if seed == -1: # seedÍ∞Ä -1Ïù¥Î©¥ ÎûúÎç§ (ComfyUI ÏúÑÏ†Ø ÌäπÏÑ±ÏÉÅ randomize string ÎåÄÏã† -1 int Ï≤¥ÌÅ¨Í∞Ä ÏùºÎ∞òÏ†ÅÏù¥ÎÇò, string ÏûÖÎ†•Ïù¥ ÏûàÎã§Î©¥ Î≥ÄÌôò)
             seed = int(time.time_ns() % (2**31))

        # 3) Î©îÏãúÏßÄ Íµ¨ÏÑ±
        url = f"http://{ip_address}:{port}/v1/chat/completions"
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})

        # ÏΩòÌÖêÏ∏† Î¶¨Ïä§Ìä∏ ÏÉùÏÑ± (ÌÖçÏä§Ìä∏ + nÍ∞úÏùò Ïù¥ÎØ∏ÏßÄ)
        content_list = [{"type": "text", "text": user_prompt or "Describe the images."}]

        # Ïù¥ÎØ∏ÏßÄ Ï≤òÎ¶¨ (Î∞∞Ïπò ÏßÄÏõê)
        if image is not None:
            # image shapeÏùÄ Î≥¥ÌÜµ [Batch, Height, Width, Channels]
            batch_count = image.shape[0]
            
            for i in range(batch_count):
                # Î∞∞ÏπòÏóêÏÑú iÎ≤àÏß∏ Ïù¥ÎØ∏ÏßÄÎßå Ï∂îÏ∂ú (H,W,C)
                img_slice = image[i]
                image_url = self._convert_single_image_to_base64(img_slice)
                
                if image_url:
                    content_list.append({
                        "type": "image_url", 
                        "image_url": {"url": image_url}
                    })

        messages.append({"role": "user", "content": content_list})

        body = {
            "model": model_key,
            "messages": messages,
            "max_tokens": int(max_tokens),
            "temperature": float(temperature),
            "seed": int(seed),
        }

        # 4) Ìò∏Ï∂ú
        try:
            resp = requests.post(url, json=body, timeout=timeout_seconds)
            resp.raise_for_status()
            data = resp.json()
        except Exception as e:
            # ÏóêÎü¨ Î∞úÏÉù Ïãú ÏÉÅÏÑ∏ ÎÇ¥Ïö© Î∞òÌôò (ÎîîÎ≤ÑÍπÖÏö©)
            return (f"Error: {e}",)

        # 5) ÏùëÎãµ ÌååÏã±
        try:
            text = data["choices"][0]["message"]["content"]
        except Exception:
            text = json.dumps(data, ensure_ascii=False)

        # 6) ÏûêÎèô Ïñ∏Î°úÎìú
        if auto_unload and unload_delay > 0:
            time.sleep(unload_delay)
            unload_endpoints = [
                f"http://{ip_address}:{port}/v1/models/unload",
                f"http://{ip_address}:{port}/v1/unload"
            ]
            for u in unload_endpoints:
                try:
                    requests.post(u, json={"model": model_key}, timeout=2)
                except Exception:
                    pass

        return (text,)

# Îì±Î°ù
NODE_CLASS_MAPPINGS = {
    "DINKI LM Studio Assistant": DINKI_LMStudio,
}
NODE_DISPLAY_NAME_MAPPINGS = {
    "DINKI LM Studio Assistant": "DINKI LM Studio Assistant",
}